{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22e5ecd5",
   "metadata": {},
   "source": [
    "# ETL Galaxy Zoo 2 - Prepare Data\n",
    "\n",
    "by BRAUX Owen and CAMBIER Elliot in 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d80282a",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf62d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff8303b",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351c28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_RAW_DIR = os.path.join(BASE_DIR, 'data_raw')\n",
    "IMAGES_DIR = os.path.join(BASE_DIR, 'dataset_images')\n",
    "CSV_PATH = \"gz2_hart16.csv.gz\"\n",
    "SDSS_URL = \"http://skyserver.sdss.org/dr16/SkyServerWS/ImgCutout/getjpeg\"\n",
    "GZ2_URL = \"https://gz2hart.s3.amazonaws.com/gz2_hart16.csv.gz\"\n",
    "\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    print(\"Downloading Galaxy Zoo 2 metadata...\")\n",
    "    r = requests.get(GZ2_URL)\n",
    "    with open(CSV_PATH, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    print(\"Download complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6653fbd7",
   "metadata": {},
   "source": [
    "## Mapping of galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe0655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPPING GALAXIES :\n",
    "# main probabilities\n",
    "col_smooth = 't01_smooth_or_features_a01_smooth_debiased'\n",
    "col_features = 't01_smooth_or_features_a02_features_or_disk_debiased'\n",
    "col_edgeon = 't02_edgeon_a04_yes_debiased' \n",
    "col_bar = 't03_bar_a06_bar_debiased'      \n",
    "col_spiral = 't04_spiral_a08_spiral_debiased' \n",
    "\n",
    "# rounded a16 and a18\n",
    "col_round = 't07_rounded_a16_completely_round_debiased'\n",
    "col_cigar = 't07_rounded_a18_cigar_shaped_debiased'\n",
    "\n",
    "# Winding\n",
    "col_tight = 't10_arms_winding_a28_tight_debiased'\n",
    "col_medium = 't10_arms_winding_a29_medium_debiased'\n",
    "col_loose = 't10_arms_winding_a30_loose_debiased'\n",
    "\n",
    "# Fusion\n",
    "col_merger = 't08_odd_feature_a24_merger_debiased'\n",
    "\n",
    "CLASS_NAMES = {\n",
    "    0: \"0_Elliptique_Ronde\",\n",
    "    1: \"1_Elliptique_Allongee\",\n",
    "    2: \"2_Lenticulaire\",\n",
    "    3: \"3_Spirale_Serree\",\n",
    "    4: \"4_Spirale_Moyenne\",\n",
    "    5: \"5_Spirale_Lache\",\n",
    "    6: \"6_Barree_Serree\",\n",
    "    7: \"7_Barree_Moyenne\",\n",
    "    8: \"8_Barree_Lache\",\n",
    "    9: \"9_Merger_Irreguliere\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e69d40a",
   "metadata": {},
   "source": [
    "## Creating Folders for classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a33b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "for folder_name in CLASS_NAMES.values():\n",
    "    os.makedirs(os.path.join(IMAGES_DIR, folder_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac98bd84",
   "metadata": {},
   "source": [
    "## Main ETL logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf22afe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_galaxy_class(row):\n",
    "    try:     \n",
    "        # CASE 1 : ROUND\n",
    "        if row[col_smooth] > 0.8:\n",
    "            if row[col_cigar] > 0.5:\n",
    "                return 1 # E4-E7 \n",
    "            elif row[col_round] > 0.5:\n",
    "                return 0 # E0-E3 \n",
    "            else:\n",
    "                return 0 # DEFAULT E0-E3\n",
    "\n",
    "        # CASE 2 : Merger\n",
    "        if row[col_merger] > 0.6:\n",
    "            return 9 \n",
    "\n",
    "        # CASE 3 :S & S0\n",
    "        if row[col_features] > 0.5 and row[col_edgeon] < 0.5:\n",
    "            \n",
    "            # S0\n",
    "            if row[col_spiral] < 0.5:\n",
    "                return 2 \n",
    "                \n",
    "            # Barre ?\n",
    "            is_barred = (row[col_bar] > 0.5)\n",
    "            \n",
    "            # windings (Tight / Medium / Loose)\n",
    "            winding_scores = [row[col_tight], row[col_medium], row[col_loose]]\n",
    "            max_winding = np.argmax(winding_scores) \n",
    "            \n",
    "            if is_barred:\n",
    "                if max_winding == 0: return 6 # SBa\n",
    "                if max_winding == 1: return 7 # SBb\n",
    "                if max_winding == 2: return 8 # SBc\n",
    "            else:\n",
    "                if max_winding == 0: return 3 # Sa\n",
    "                if max_winding == 1: return 4 # Sb\n",
    "                if max_winding == 2: return 5 # Sc\n",
    "\n",
    "        return -1 # trash\n",
    "    \n",
    "    except KeyError:\n",
    "        return -1\n",
    "\n",
    "def download_image_worker(row):\n",
    "    try:\n",
    "        label = row['label']\n",
    "        objid = str(row['dr7objid'])\n",
    "        ra = row['ra']\n",
    "        dec = row['dec']\n",
    "        \n",
    "        folder = CLASS_NAMES[label]\n",
    "        filepath = os.path.join(IMAGES_DIR, folder, f\"{objid}.jpg\")\n",
    "        \n",
    "        # skip if already exists\n",
    "        if os.path.exists(filepath):\n",
    "            return \"EXIST\"\n",
    "\n",
    "        params = {\n",
    "            'ra': ra, 'dec': dec, 'scale': 0.396, \n",
    "            'width': 128, 'height': 128, 'opt': ''\n",
    "        }\n",
    "        \n",
    "        # slightly longer timeout since we share bandwidth\n",
    "        response = requests.get(SDSS_URL, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        img.save(filepath)\n",
    "        return \"OK\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return \"ERROR\"\n",
    "    \n",
    "\n",
    "\n",
    "def run_pipeline(csv_file, target_per_class=2000, max_workers=10):\n",
    "    print(f\"Chargement du CSV '{csv_file}'...\")\n",
    "    if not os.path.exists(csv_file):\n",
    "        raise FileNotFoundError(f\"Le fichier {csv_file} est introuvable !\")\n",
    "        \n",
    "    df = pd.read_csv(csv_file, compression='gzip')\n",
    "    print(\"   -> Application de l'arbre de décision...\")\n",
    "    df['label'] = df.apply(get_galaxy_class, axis=1)\n",
    "\n",
    "    # cleaning\n",
    "    df_clean = df[df['label'] != -1].copy()\n",
    "    print(f\"   -> Galaxies classifiées valides : {len(df_clean)}\")\n",
    "\n",
    "    # Sampling\n",
    "    print(\"\\nÉquilibrage...\")\n",
    "    dfs_list = []\n",
    "    \n",
    "    for label in range(10):\n",
    "        df_class = df_clean[df_clean['label'] == label]\n",
    "        count = len(df_class)\n",
    "        print(f\"   -> Classe {label} [{CLASS_NAMES[label]}] : {count} dispo\", end=\"\")\n",
    "        \n",
    "        if count > target_per_class:\n",
    "            df_sampled = df_class.sample(n=target_per_class, random_state=42)\n",
    "            print(f\" -> {target_per_class} gardées\")\n",
    "        else:\n",
    "            df_sampled = df_class\n",
    "            print(f\" -> Tout gardé\")\n",
    "        \n",
    "        dfs_list.append(df_sampled)\n",
    "\n",
    "    df_final = pd.concat(dfs_list).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Medium csv \n",
    "    df_final.to_csv(\"dataset_metadata.csv\", index=False)\n",
    "    print(f\"   -> Dataset final prêt : {len(df_final)} images à récupérer.\")\n",
    "\n",
    "    # DOWNLOAD\n",
    "    print(f\"\\nLancement du téléchargement ({max_workers} threads)...\")\n",
    "    \n",
    "    results = {\"OK\": 0, \"EXIST\": 0, \"ERROR\": 0}\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(download_image_worker, row): row for _, row in df_final.iterrows()}\n",
    "        for future in tqdm(as_completed(futures), total=len(df_final), unit=\"img\"):\n",
    "            res = future.result()\n",
    "            results[res] += 1\n",
    "            \n",
    "    print(f\"-> Résultat : {results}\")\n",
    "\n",
    "    # D. ARCHIVAGE\n",
    "    print(\"\\nCréation de l'archive ZIP...\")\n",
    "    output_filename = \"dataset_galaxies\"\n",
    "    shutil.make_archive(output_filename, 'zip', IMAGES_DIR)\n",
    "    print(f\"L'archive '{output_filename}.zip' est prête.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcfc468",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        run_pipeline(CSV_PATH)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur : {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
